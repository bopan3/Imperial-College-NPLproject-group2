{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Mode: 我 来到 北京               \n",
      "             清华大学\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "strs=[\"我来到北京清华大学\",\"乒乓球拍卖完了\",\"中国科学技术大学\"]\n",
    "seg_list = jieba.cut(\"我来到北京       \\n      清华大学\", cut_all=False)\n",
    "print(\"Default Mode: \" + \" \".join(seg_list))  # 精确模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-17 17:55:04,182 : INFO : collecting all words and their counts\n",
      "2020-08-17 17:55:04,276 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-08-17 17:55:04,283 : INFO : collected 11 word types from a corpus of 11 raw words and 7 sentences\n",
      "2020-08-17 17:55:04,293 : INFO : Loading a fresh vocabulary\n",
      "2020-08-17 17:55:04,296 : INFO : effective_min_count=1 retains 11 unique words (100% of original 11, drops 0)\n",
      "2020-08-17 17:55:04,300 : INFO : effective_min_count=1 leaves 11 word corpus (100% of original 11, drops 0)\n",
      "2020-08-17 17:55:04,309 : INFO : deleting the raw counts dictionary of 11 items\n",
      "2020-08-17 17:55:04,312 : INFO : sample=0.001 downsamples 11 most-common words\n",
      "2020-08-17 17:55:04,313 : INFO : downsampling leaves estimated 1 word corpus (11.6% of prior 11)\n",
      "2020-08-17 17:55:04,315 : INFO : estimated required memory for 11 words and 100 dimensions: 14300 bytes\n",
      "2020-08-17 17:55:04,316 : INFO : resetting layer weights\n",
      "2020-08-17 17:55:04,332 : INFO : training model with 3 workers on 11 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-08-17 17:55:04,336 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-17 17:55:04,338 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-17 17:55:04,340 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-17 17:55:04,341 : INFO : EPOCH - 1 : training on 11 raw words (1 effective words) took 0.0s, 174 effective words/s\n",
      "2020-08-17 17:55:04,346 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-17 17:55:04,348 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-17 17:55:04,350 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-17 17:55:04,351 : INFO : EPOCH - 2 : training on 11 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2020-08-17 17:55:04,355 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-17 17:55:04,357 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-17 17:55:04,358 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-17 17:55:04,360 : INFO : EPOCH - 3 : training on 11 raw words (2 effective words) took 0.0s, 440 effective words/s\n",
      "2020-08-17 17:55:04,365 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-17 17:55:04,366 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-17 17:55:04,368 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-17 17:55:04,370 : INFO : EPOCH - 4 : training on 11 raw words (0 effective words) took 0.0s, 0 effective words/s\n",
      "2020-08-17 17:55:04,376 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-17 17:55:04,377 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-17 17:55:04,379 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-17 17:55:04,380 : INFO : EPOCH - 5 : training on 11 raw words (1 effective words) took 0.0s, 197 effective words/s\n",
      "2020-08-17 17:55:04,382 : INFO : training on a 55 raw words (4 effective words) took 0.0s, 82 effective words/s\n",
      "2020-08-17 17:55:04,383 : WARNING : under 10 jobs per worker: consider setting a smaller `batch_words' for smoother alpha decay\n"
     ]
    }
   ],
   "source": [
    "# import modules & set up logging\n",
    "import gensim, logging,os\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    " \n",
    "#sentences = [['first', 'sentence'], ['second', 'sentence']]\n",
    "# train word2vec on the two sentences\n",
    "#model = gensim.models.Word2Vec(sentences, min_count=1)\n",
    "\n",
    "\n",
    "class MySentences(object):\n",
    "    def __init__(self, dirname):\n",
    "        self.dirname = dirname\n",
    " \n",
    "    def __iter__(self):\n",
    "        for fname in os.listdir(self.dirname):\n",
    "            if fname[0]!='.':\n",
    "                for line in open(os.path.join(self.dirname, fname)):\n",
    "                    yield line.split()\n",
    "                \n",
    "sentences = MySentences('try/') # a memory-friendly iterator\n",
    "\n",
    "\n",
    "\n",
    "model = gensim.models.Word2Vec(sentences,min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md           Untitled.ipynb      \u001b[34mafter_t2s\u001b[m\u001b[m           \u001b[34mtext\u001b[m\u001b[m\r\n",
      "\u001b[34mSpoon-Knife\u001b[m\u001b[m         WordEmbedding.ipynb team log.md         try\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
